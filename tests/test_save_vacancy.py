"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ –ø—Ä–∏–º–µ—Ä—ã –≤–∞–∫–∞–Ω—Å–∏–π
"""
import json
import sys
import codecs
from pathlib import Path
from collections import Counter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

def check_vacancies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"""
    vacancies_file = Path("data/vacancies.json")
    
    if not vacancies_file.exists():
        print("‚ùå –§–∞–π–ª vacancies.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å–∫–∞–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥")
        return
    
    try:
        with open(vacancies_file, "r", encoding="utf-8") as f:
            vacancies = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return
    
    if not vacancies:
        print("‚ö†Ô∏è  –§–∞–π–ª vacancies.json –ø—É—Å—Ç")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å")
        return
    
    print("=" * 60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–ê–ö–ê–ù–°–ò–ô")
    print("=" * 60)
    print(f"\nüìä –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    sources = Counter()
    channels = Counter()
    new_count = 0
    
    for v in vacancies:
        source = v.get("source", "telegram")  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é telegram –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
        sources[source] += 1
        
        channel = v.get("channel", "Unknown")
        channels[channel] += 1
        
        if v.get("is_new", False):
            new_count += 1
    
    print(f"\nüìà –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
    for source, count in sources.most_common():
        source_name = {
            "telegram": "üì± Telegram",
            "headhunter": "üéØ HeadHunter",
            "linkedin": "üîó LinkedIn",
            "habr": "üíº Habr",
            "custom": "üìù Custom"
        }.get(source, f"‚ùì {source}")
        print(f"   {source_name}: {count}")
    
    print(f"\nüìå –ù–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {new_count}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ —Å HeadHunter/LinkedIn
    hh_vacancies = [v for v in vacancies if v.get("source") == "headhunter"]
    li_vacancies = [v for v in vacancies if v.get("source") == "linkedin"]
    
    print(f"\nüéØ HeadHunter –≤–∞–∫–∞–Ω—Å–∏–π: {len(hh_vacancies)}")
    print(f"üîó LinkedIn –≤–∞–∫–∞–Ω—Å–∏–π: {len(li_vacancies)}")
    
    if hh_vacancies:
        print("\n" + "=" * 60)
        print("–ü–†–ò–ú–ï–†–´ –í–ê–ö–ê–ù–°–ò–ô –° HEADHUNTER")
        print("=" * 60)
        for i, vac in enumerate(hh_vacancies[:3], 1):
            print(f"\n{i}. ID: {vac.get('id', 'N/A')[:8]}...")
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {vac.get('title', 'N/A')}")
            print(f"   –ö–æ–º–ø–∞–Ω–∏—è: {vac.get('channel', 'N/A')}")
            print(f"   –î–∞—Ç–∞: {vac.get('date', 'N/A')}")
            print(f"   –°—Å—ã–ª–∫–∞: {vac.get('link', 'N/A')}")
            print(f"   –ù–æ–≤–æ–µ: {'–î–∞' if vac.get('is_new') else '–ù–µ—Ç'}")
            text_preview = vac.get('text', '')[:150].replace('\n', ' ')
            print(f"   –¢–µ–∫—Å—Ç: {text_preview}...")
    
    if li_vacancies:
        print("\n" + "=" * 60)
        print("–ü–†–ò–ú–ï–†–´ –í–ê–ö–ê–ù–°–ò–ô –° LINKEDIN")
        print("=" * 60)
        for i, vac in enumerate(li_vacancies[:3], 1):
            print(f"\n{i}. ID: {vac.get('id', 'N/A')[:8]}...")
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {vac.get('title', 'N/A')}")
            print(f"   –ö–æ–º–ø–∞–Ω–∏—è: {vac.get('channel', 'N/A')}")
            print(f"   –î–∞—Ç–∞: {vac.get('date', 'N/A')}")
            print(f"   –°—Å—ã–ª–∫–∞: {vac.get('link', 'N/A')}")
            print(f"   –ù–æ–≤–æ–µ: {'–î–∞' if vac.get('is_new') else '–ù–µ—Ç'}")
            text_preview = vac.get('text', '')[:150].replace('\n', ' ')
            print(f"   –¢–µ–∫—Å—Ç: {text_preview}...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–•")
    print("=" * 60)
    
    required_fields = ["id", "channel", "text", "date"]
    missing_fields = Counter()
    
    for vac in vacancies:
        for field in required_fields:
            if field not in vac:
                missing_fields[field] += 1
    
    if missing_fields:
        print("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:")
        for field, count in missing_fields.items():
            print(f"   {field}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ {count} –≤–∞–∫–∞–Ω—Å–∏—è—Ö")
    else:
        print("‚úÖ –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–º–µ—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–µ source
    vacancies_without_source = [v for v in vacancies if "source" not in v]
    if vacancies_without_source:
        print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(vacancies_without_source)} –≤–∞–∫–∞–Ω—Å–∏–π –±–µ–∑ –ø–æ–ª—è 'source'")
        print("   –≠—Ç–æ —Å—Ç–∞—Ä—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ Telegram (–¥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–æ–≤)")
        print("   –û–Ω–∏ –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –∫–∞–∫ 'telegram'")
    else:
        print("\n‚úÖ –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–º–µ—é—Ç –ø–æ–ª–µ 'source'")
    
    print("\n" + "=" * 60)
    print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print("=" * 60)
    
    if len(hh_vacancies) == 0 and len(li_vacancies) == 0:
        print("\n‚ö†Ô∏è  –í–∞–∫–∞–Ω—Å–∏–∏ —Å HeadHunter –∏ LinkedIn –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("   1. –í–∫–ª—é—á–µ–Ω—ã –ª–∏ –ø–∞—Ä—Å–µ—Ä—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö (enable_headhunter, enable_linkedin)")
        print("   2. –£–∫–∞–∑–∞–Ω—ã –ª–∏ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (hh_search_query, linkedin_search_query)")
        print("   3. –ó–∞–ø—É—Å–∫–∞–ª—Å—è –ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ—Å–ª–µ –≤–∫–ª—é—á–µ–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–æ–≤")
        print("   4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫")
    else:
        print("\n‚úÖ –í–∞–∫–∞–Ω—Å–∏–∏ —Å HeadHunter/LinkedIn –Ω–∞–π–¥–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
        print("   –ï—Å–ª–∏ –æ–Ω–∏ –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ:")
        print("   1. –û–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É (F5)")
        print("   2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Å–æ–ª—å –±—Ä–∞—É–∑–µ—Ä–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫")

if __name__ == "__main__":
    check_vacancies()
